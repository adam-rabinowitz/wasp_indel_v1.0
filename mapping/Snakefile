configfile: 'snakemake_config.yml'

# Get read pairing
if len(config['fastq']) == 1:
    pair = False
elif len(config['fastq']) == 2:
    pair = True
else:
    raise ValueError('1 or 2 input fastq files expected')

# Generate a filtered BAM file with duplicates removed
rule all:
    input:
        config['out_prefix'] + '.filtered.rmdup.bam',
        config['out_prefix'] + '.filtered.rmdup.bai',
        config['out_prefix'] + '.filtered.rmdup.log',
        config['out_prefix'] + '.variant_log.txt',
        config['out_prefix'] + '.filter_log.txt',
        config['out_prefix'] + '.variant_counts.txt'

# Align initial fastq reads to the genome
rule first_alignment:
    input:
        config['fastq']
    output:
        temp(config['out_prefix'] + '.initial.sam')
    params:
        fasta = config['fasta'],
        rg = config['read_group']
    shell:
        'bwa mem -R "{params[rg]}" {params[fasta]} {input} > {output}'

# Convert initial alignment to coordinate sorted BAM file
rule sort_first_alignment:
    input:
        config['out_prefix'] + '.initial.sam'
    output:
        bam = temp(config['out_prefix'] + '.initial.bam'),
        bai = temp(config['out_prefix'] + '.initial.bai')
    shell:
        'picard SortSam -I {input} -O {output.bam} -SO coordinate '
        '--CREATE_INDEX true'

# Place alignments not overlapping variants in a BAM file and extract reads
# overlapping variants, and their allele flipped versions, to a fastq file.
rule filter_first_alignment:
    input:
        bam = config['out_prefix'] + '.initial.bam',
        bai = config['out_prefix'] + '.initial.bai',
        vcf = config['vcf']
    output:
        bam = temp(config['out_prefix'] + '.invariant.bam'),
        fastq = temp(config['out_prefix'] + '.remap.fq.gz'),
        log = config['out_prefix'] + '.variant_log.txt'
    params:
        script = config['wasp'] + '/generate_variant_reads.py',
        prefix = config['out_prefix'],
        paired = lambda wildcards, pair=pair: '--paired_end' if pair else ''
    shell:
        "python {params[script]} {params[paired]} {input.bam} {input.vcf} "
        "{params[prefix]}"

# Realign reads along with their allele flipped versions
rule second_alignment:
    input:
        config['out_prefix'] + '.remap.fq.gz'
    output:
        temp(config['out_prefix'] + '.remap.sam')
    params:
        fasta = config['fasta'],
        rg = config['read_group'],
        paired = lambda wildcards, pair=pair: '-p' if pair else ''
    shell:
        'bwa mem -R "{params[rg]}" {params[paired]} {params[fasta]} {input} > '
        '{output}'

# Sort second alignment by read name
rule sort_second_alignment:
    input:
        config['out_prefix'] + '.remap.sam'
    output:
        temp(config['out_prefix'] + '.remap.bam')
    shell:
        'picard SortSam -I {input} -O {output} -SO queryname'

# Extract reads for which the original and allele flipped version align
# to the same location
rule filter_second_alignment:
    input:
        config['out_prefix'] + '.remap.bam'
    output:
        temp(config['out_prefix'] + '.consistent.bam'),
        config['out_prefix'] + '.filter_log.txt',
    params:
        script = config['wasp'] + '/filter_remapped_reads.py',
        prefix = config['out_prefix'],
        paired = lambda wildcards, pair=pair: '--paired_end' if pair else '',
        wobble = '--wobble ' + str(config['wobble'])
    shell:
        "python {params[script]} {params[paired]} {params[wobble]} "
        "{input} {params[prefix]}"

# Merge all passed alignments
rule merge_alignments:
    input:
        bam1 = config['out_prefix'] + '.invariant.bam',
        bam2 = config['out_prefix'] + '.consistent.bam'
    output:
        temp(config['out_prefix'] + '.filtered.bam')
    shell:
        'picard GatherBamFiles -I {input.bam1} -I {input.bam2} -O {output}'

# Sort passed alignments
rule sort_merged_bam:
    input:
        config['out_prefix'] + '.filtered.bam',
    output:
        bam = temp(config['out_prefix'] + '.filtered.sorted.bam'),
        bai = temp(config['out_prefix'] + '.filtered.sorted.bai')
    shell:
        'picard SortSam -I {input} -O {output.bam} -SO coordinate '
        '--CREATE_INDEX true'

# Remove duplicate alignments randomly so as not to favour a specific allele
rule randomly_remove_duplicates:
    input:
        bam = config['out_prefix'] + '.filtered.sorted.bam',
        bai = config['out_prefix'] + '.filtered.sorted.bai'
    output:
        bam = config['out_prefix'] + '.filtered.rmdup.bam',
        bai = config['out_prefix'] + '.filtered.rmdup.bai',
        log = config['out_prefix'] + '.filtered.rmdup.log'
    shell:
        'picard MarkDuplicates -I {input.bam} -M {output.log} -O {output.bam} '
        '--ASSUME_SORTED --DUPLICATE_SCORING_STRATEGY RANDOM '
        '--REMOVE_DUPLICATES true --CREATE_INDEX true'

# Get variant counts from filtered and deduplicated BAM file
rule get_variant_counts:
    input:
        bam = config['out_prefix'] + '.filtered.rmdup.bam',
        bai = config['out_prefix'] + '.filtered.rmdup.bai',
        vcf = config['vcf']
    output:
        config['out_prefix'] + '.variant_counts.txt'
    params:
        script = config['wasp'] + '/get_as_counts.py',
        paired = lambda wildcards, pair=pair: '--paired_end' if pair else ''
    shell:
        'python {params[script]} {params[paired]} {input.bam} {input.vcf} '
        '{output}'
